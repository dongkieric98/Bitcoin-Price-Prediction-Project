{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 라이브러리 및 데이터 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\nt930qcg\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1\n",
      "  Downloading tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "Collecting tensorboard<2.17,>=2.16\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Collecting keras>=3.0.0\n",
      "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.63.0-cp39-cp39-win_amd64.whl (3.9 MB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\nt930qcg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl (37 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\nt930qcg\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nt930qcg\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
      "Collecting h5py>=3.10.0\n",
      "  Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nt930qcg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (56.0.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nt930qcg\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.3-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl (127 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.11.0-cp39-cp39-win_amd64.whl (240 kB)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl (100 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\nt930qcg\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nt930qcg\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.18.1)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nt930qcg\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, MarkupSafe, markdown-it-py, wheel, werkzeug, urllib3, tensorboard-data-server, rich, protobuf, optree, namex, ml-dtypes, markdown, idna, h5py, grpcio, charset-normalizer, certifi, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard, requests, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.2.2 charset-normalizer-3.3.2 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.63.0 h5py-3.11.0 idna-3.7 keras-3.3.3 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 protobuf-4.25.3 requests-2.31.0 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 urllib3-2.2.1 werkzeug-3.0.3 wheel-0.43.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "submission = pd.read_csv('data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. 데이터 기초 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처음,끝부분 확인\n",
    "head = train.head(5)\n",
    "tail = train.head(5)\n",
    "\n",
    "# Columns 확인\n",
    "columns = train.columns\n",
    "\n",
    "# Data Shape 확인\n",
    "shape = train.shape\n",
    "\n",
    "# 통계값 확인\n",
    "describe = train.describe()\n",
    "\n",
    "# Columns Type 확인\n",
    "dtypes = train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. 결측치 확인\n",
    "###### [1] 결측치와 중복되는 행이 모두 없음을 확인할 수 있다\n",
    "###### [2] 따라서 결측치 처리에 대한 부분이 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼별 결측치 파악\n",
    "null = train.isna().sum()\n",
    "\n",
    "# 중복되는 행 파악\n",
    "duplicated = train[train.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. 시간 데이터 전처리\n",
    "###### [1] 시간 기반 데이터는 Time 컬럼을 인덱스로 설정하면 시간 시계열 분석에 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. time 컬럼을 datetime 형식으로 변환\n",
    "train['Time'] = pd.to_datetime(train['Time'])\n",
    "\n",
    "# 02. 년, 월, 일, 시, 분, 초 등의 특성 추출\n",
    "train['year'] = train['Time'].dt.year\n",
    "train['month'] = train['Time'].dt.month\n",
    "train['day'] = train['Time'].dt.day\n",
    "train['hour'] = train['Time'].dt.hour\n",
    "train['minute'] = train['Time'].dt.minute\n",
    "train['second'] = train['Time'].dt.second\n",
    "\n",
    "# 03. 요일 추출 (0=월요일, 6=일요일)\n",
    "train['weekday'] = train['Time'].dt.weekday\n",
    "\n",
    "# 04. 주차 추출\n",
    "train['week'] = train['Time'].dt.isocalendar().week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NT930QCG\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 58ms/step - loss: 0.0020\n",
      "Epoch 2/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 62ms/step - loss: 4.9588e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 71ms/step - loss: 3.4630e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 68ms/step - loss: 2.7682e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 56ms/step - loss: 2.4808e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 57ms/step - loss: 1.6752e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 37ms/step - loss: 1.4281e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 55ms/step - loss: 1.4059e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 56ms/step - loss: 1.4475e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 53ms/step - loss: 1.4402e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 44ms/step - loss: 1.4760e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 44ms/step - loss: 1.3265e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 63ms/step - loss: 1.3616e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 60ms/step - loss: 1.2808e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 63ms/step - loss: 1.3011e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 71ms/step - loss: 1.2633e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m1704/1704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 58ms/step - loss: 1.3294e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m 870/1704\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 69ms/step - loss: 1.1838e-05"
     ]
    }
   ],
   "source": [
    "# 데이터 읽기\n",
    "train = pd.read_csv('data/train.csv')\n",
    "submission = pd.read_csv('data/submission.csv')\n",
    "\n",
    "# 01. time 컬럼을 datetime 형식으로 변환\n",
    "train['Time'] = pd.to_datetime(train['Time'])\n",
    "\n",
    "# 02. 년, 월, 일, 시, 분, 초 등의 특성 추출\n",
    "train['year'] = train['Time'].dt.year\n",
    "train['month'] = train['Time'].dt.month\n",
    "train['day'] = train['Time'].dt.day\n",
    "train['hour'] = train['Time'].dt.hour\n",
    "train['minute'] = train['Time'].dt.minute\n",
    "train['second'] = train['Time'].dt.second\n",
    "\n",
    "# 03. 요일 추출 (0=월요일, 6=일요일)\n",
    "train['weekday'] = train['Time'].dt.weekday\n",
    "\n",
    "# 04. 주차 추출\n",
    "train['week'] = train['Time'].dt.isocalendar().week\n",
    "\n",
    "# 비트코인 가격 예측을 위한 종가(Close) 컬럼 선택\n",
    "data = train[['Time', 'Close']].set_index('Time')\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 학습 데이터 준비\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 60\n",
    "X, Y = create_dataset(scaled_data, look_back)\n",
    "\n",
    "# 데이터 셰이프 변환 [samples, time steps, features]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# LSTM 모델 구축\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(look_back, 1)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# 예측\n",
    "predicted = model.predict(X)\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "\n",
    "# 결과 시각화\n",
    "plt.plot(data.index[look_back+1:], data.values[look_back+1:], label='Actual')\n",
    "plt.plot(data.index[look_back+1:], predicted, label='Predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내일 실행해볼 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 데이터 읽기\n",
    "train = pd.read_csv('data/train.csv')\n",
    "submission = pd.read_csv('data/submission.csv')\n",
    "\n",
    "# 01. time 컬럼을 datetime 형식으로 변환\n",
    "train['Time'] = pd.to_datetime(train['Time'])\n",
    "submission['Time'] = pd.to_datetime(submission['Time'])\n",
    "\n",
    "# 02. 년, 월, 일, 시, 분, 초 등의 특성 추출\n",
    "train['year'] = train['Time'].dt.year\n",
    "train['month'] = train['Time'].dt.month\n",
    "train['day'] = train['Time'].dt.day\n",
    "train['hour'] = train['Time'].dt.hour\n",
    "train['minute'] = train['Time'].dt.minute\n",
    "train['second'] = train['Time'].dt.second\n",
    "\n",
    "submission['year'] = submission['Time'].dt.year\n",
    "submission['month'] = submission['Time'].dt.month\n",
    "submission['day'] = submission['Time'].dt.day\n",
    "submission['hour'] = submission['Time'].dt.hour\n",
    "submission['minute'] = submission['Time'].dt.minute\n",
    "submission['second'] = submission['Time'].dt.second\n",
    "\n",
    "# 03. 요일 추출 (0=월요일, 6=일요일)\n",
    "train['weekday'] = train['Time'].dt.weekday\n",
    "submission['weekday'] = submission['Time'].dt.weekday\n",
    "\n",
    "# 04. 주차 추출\n",
    "train['week'] = train['Time'].dt.isocalendar().week\n",
    "submission['week'] = submission['Time'].dt.isocalendar().week\n",
    "\n",
    "# 비트코인 가격 예측을 위한 종가(Close) 컬럼 선택\n",
    "data = train[['Time', 'Close']].set_index('Time')\n",
    "submission_data = submission.set_index('Time')\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 학습 데이터 준비\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 60\n",
    "X, Y = create_dataset(scaled_data, look_back)\n",
    "\n",
    "# 데이터 셰이프 변환 [samples, time steps, features]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# LSTM 모델 구축\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(look_back, 1)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# 학습된 모델을 사용하여 submission 데이터 예측\n",
    "submission_scaled_data = scaler.transform(submission_data)\n",
    "submission_X = []\n",
    "for i in range(len(submission_scaled_data) - look_back):\n",
    "    submission_X.append(submission_scaled_data[i:(i + look_back), 0])\n",
    "\n",
    "submission_X = np.array(submission_X)\n",
    "submission_X = np.reshape(submission_X, (submission_X.shape[0], submission_X.shape[1], 1))\n",
    "\n",
    "# 예측\n",
    "submission_predict = model.predict(submission_X)\n",
    "submission_predict = scaler.inverse_transform(submission_predict)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "submission_result = pd.DataFrame(submission_predict, columns=['Predicted_Close'])\n",
    "submission_result['Time'] = submission['Time'][look_back:].values\n",
    "\n",
    "# 결과 저장\n",
    "submission_result.to_csv('submission_predictions.csv', index=False)\n",
    "\n",
    "# 결과 시각화 (선택 사항)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(submission['Time'][look_back:], submission_predict, label='Predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Predicted Close Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
